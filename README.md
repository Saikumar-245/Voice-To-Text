# ğŸ¤ Voice-to-Text Desktop App (Wispr Flow Clone)

This project is a **functional clone of Wispr Flow**, focused on the **core voice-to-text workflow**. It is built using **Tauri + React.js** and integrates **Deepgram** for real-time speech recognition.

The goal of this assignment is to demonstrate practical skills in building **AI-powered, cross-platform desktop applications** with clean architecture and reliable real-time audio streaming.

---

## ğŸš€ Features

* âœ… Push-to-Talk voice input
* ğŸ™ï¸ Microphone access & audio capture
* âš¡ Real-time speech-to-text transcription using Deepgram
* ğŸ“ Live display of transcribed text
* ğŸ–¥ï¸ Desktop-ready via Tauri
* âŒ Graceful error handling (mic / network / API errors)

---

## ğŸ› ï¸ Tech Stack

* **Tauri** â€“ Cross-platform desktop framework (Windows, macOS, Linux)
* **React.js** â€“ Frontend UI and state management
* **Deepgram API** â€“ Real-time speech-to-text transcription
* **Web Audio API** â€“ Microphone access and audio streaming

---

## ğŸ“ Project Structure

```
src/
â”‚
â”œâ”€â”€ App.jsx          # Main UI and push-to-talk logic
â”œâ”€â”€ main.jsx         # React entry point
â”œâ”€â”€ Audio.jsx        # Microphone access & audio capture logic
â”œâ”€â”€ Deepgram.jsx     # Deepgram WebSocket transcription service
â”œâ”€â”€ styles.css       # Basic styling
â”‚
â””â”€â”€ assets/
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone <your-repo-url>
cd wispr-flow-clone
```

### 2ï¸âƒ£ Install Dependencies

```bash
npm install
```

### 3ï¸âƒ£ Add Deepgram API Key

Create a `.env` file in the root directory:

```env
VITE_DEEPGRAM_API_KEY=your_deepgram_api_key_here
```

> âš ï¸ Do not commit your API key to GitHub.

### 4ï¸âƒ£ Run in Development Mode

```bash
npm run tauri dev
```

---

## ğŸ§  Application Architecture

The application follows a **clean separation of concerns**:

### UI Layer (React)

* Handles user interaction (push-to-talk button)
* Displays transcription results

### Audio Layer (`Audio.jsx`)

* Manages microphone permissions
* Captures audio using `MediaRecorder`
* Streams audio chunks at regular intervals

### Transcription Layer (`Deepgram.jsx`)

* Manages WebSocket connection to Deepgram
* Sends audio chunks for transcription
* Receives and parses real-time transcript results

This modular design makes the app **easy to maintain and extend**.

---

## ğŸ¯ Core Workflow

1. User presses and holds the **Push-to-Talk** button
2. Microphone access is requested
3. Audio is captured and streamed to Deepgram
4. Deepgram returns real-time transcription
5. Transcribed text is displayed in the UI
6. Releasing the button stops recording

---

## âš ï¸ Error Handling

The app gracefully handles:

* âŒ Microphone permission denial
* âŒ WebSocket connection issues
* âŒ Missing or invalid API keys

Errors are logged and do not crash the application.

---

## ğŸ§ª Known Limitations

* UI is minimal (functionality prioritized over design)
* English language transcription only
* No advanced post-processing or punctuation correction
* Audio format uses `audio/webm` for simplicity

---

## ğŸ¥ Demo Video

A demo video is provided showing:

* Push-to-talk interaction
* Real-time transcription
* Desktop application running via Tauri

(Video hosted on Google Drive / YouTube)

---

## ğŸ§© Future Improvements

* Keyboard shortcut for push-to-talk
* PCM audio streaming for higher accuracy
* Auto-insert text into active applications
* Multi-language support
* Improved UI/UX

---

## ğŸ Conclusion

This project demonstrates:

* Real-time audio streaming
* AI-powered speech recognition integration
* Clean, maintainable React architecture
* Practical use of Tauri for desktop apps

The focus was on **functionality, code quality, and user workflow**, aligning closely with real-world product requirements.

---

âœ… **Thank you for reviewing this assignment!**
